{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple example of using evolution strategies inside `es.py` for toy deterministic fitness function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import cma\n",
    "from es import SimpleGA, CMAES, PEPG, OpenES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/CMA-ES/pycma/blob/master/cma/fitness_functions.py\n",
    "def rastrigin(x):\n",
    "  \"\"\"Rastrigin test objective function, shifted by 10. units away from origin\"\"\"\n",
    "  x = np.copy(x)\n",
    "  x -= 10.0\n",
    "  if not np.isscalar(x[0]):\n",
    "    N = len(x[0])\n",
    "    return -np.array([10 * N + sum(xi**2 - 10 * np.cos(2 * np.pi * xi)) for xi in x])\n",
    "  N = len(x)\n",
    "  return -(10 * N + sum(x**2 - 10 * np.cos(2 * np.pi * x)))\n",
    "\n",
    "fit_func = rastrigin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPARAMS = 100        # make this a 100-dimensinal problem.\n",
    "NPOPULATION = 101    # use population size of 101.\n",
    "MAX_ITERATION = 4000 # run each solver for 5000 generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines a function to use solver to solve fit_func\n",
    "def test_solver(solver):\n",
    "  history = []\n",
    "  for j in range(MAX_ITERATION):\n",
    "    solutions = solver.ask()\n",
    "    fitness_list = np.zeros(solver.popsize)\n",
    "    for i in range(solver.popsize):\n",
    "      fitness_list[i] = fit_func(solutions[i])\n",
    "    solver.tell(fitness_list)\n",
    "    result = solver.result() # first element is the best solution, second element is the best fitness\n",
    "    history.append(result[1])\n",
    "    if (j+1) % 100 == 0:\n",
    "      print(\"fitness at iteration\", (j+1), result[1])\n",
    "  print(\"local optimum discovered by solver:\\n\", result[0])\n",
    "  print(\"fitness score at this local optimum:\", result[1])\n",
    "  return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros(NPARAMS) # 100-dimensional problem\n",
    "print(\"This is F(0):\")\n",
    "print(rastrigin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.ones(NPARAMS)*10. # 100-dimensional problem\n",
    "print(rastrigin(x))\n",
    "print(\"global optimum point:\\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines genetic algorithm solver\n",
    "ga = SimpleGA(NPARAMS,                # number of model parameters\n",
    "               sigma_init=0.5,        # initial standard deviation\n",
    "               popsize=NPOPULATION,   # population size\n",
    "               elite_ratio=0.1,       # percentage of the elites\n",
    "               forget_best=False,     # forget the historical best elites\n",
    "               weight_decay=0.00,     # weight decay coefficient\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit_func' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-cf3109de2aae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mga_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mga\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-1dc82117b8d8>\u001b[0m in \u001b[0;36mtest_solver\u001b[0;34m(solver)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfitness_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       \u001b[0mfitness_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolutions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitness_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# first element is the best solution, second element is the best fitness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fit_func' is not defined"
     ]
    }
   ],
   "source": [
    "ga_history = test_solver(ga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines CMA-ES algorithm solver\n",
    "cmaes = CMAES(NPARAMS,\n",
    "              popsize=NPOPULATION,\n",
    "              weight_decay=0.0,\n",
    "              sigma_init = 0.5\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cma_history = test_solver(cmaes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines PEPG (NES) solver\n",
    "pepg = PEPG(NPARAMS,                         # number of model parameters\n",
    "            sigma_init=0.5,                  # initial standard deviation\n",
    "            learning_rate=0.1,               # learning rate for standard deviation\n",
    "            learning_rate_decay=1.0,       # don't anneal the learning rate\n",
    "            popsize=NPOPULATION,             # population size\n",
    "            average_baseline=False,          # set baseline to average of batch\n",
    "            weight_decay=0.00,            # weight decay coefficient\n",
    "            rank_fitness=False,           # use rank rather than fitness numbers\n",
    "            forget_best=False)            # don't keep the historical best solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pepg_history = test_solver(pepg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines OpenAI's ES algorithm solver. Note that we needed to anneal the sigma parameter\n",
    "oes = OpenES(NPARAMS,                  # number of model parameters\n",
    "            sigma_init=0.5,            # initial standard deviation\n",
    "            sigma_decay=0.999,         # don't anneal standard deviation\n",
    "            learning_rate=0.1,         # learning rate for standard deviation\n",
    "            learning_rate_decay = 1.0, # annealing the learning rate\n",
    "            popsize=NPOPULATION,       # population size\n",
    "            antithetic=False,          # whether to use antithetic sampling\n",
    "            weight_decay=0.00,         # weight decay coefficient\n",
    "            rank_fitness=False,        # use rank rather than fitness numbers\n",
    "            forget_best=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oes_history = test_solver(oes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines OpenAI's ES algorithm solver. Note that we needed to anneal the sigma parameter\n",
    "# this version turns on antithetic sampling. It doesn't really help, and sometimes hurts performance.\n",
    "oes_antithetic = OpenES(NPARAMS,            # number of model parameters\n",
    "                 sigma_init=0.5,            # initial standard deviation\n",
    "                 sigma_decay=0.999,         # don't anneal standard deviation\n",
    "                 learning_rate=0.1,         # learning rate for standard deviation\n",
    "                 learning_rate_decay=1.0,   # annealing the learning rate\n",
    "                 popsize=NPOPULATION+1,     # population size\n",
    "                 antithetic=True,           # whether to use antithetic sampling\n",
    "                 weight_decay=0.00,         # weight decay coefficient\n",
    "                 rank_fitness=False,        # use rank rather than fitness numbers\n",
    "                 forget_best=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oes_antithetic_history = test_solver(oes_antithetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure of size 8x6 points, using 100 dots per inch\n",
    "best_history = [0] * MAX_ITERATION\n",
    "plt.figure(figsize=(16,8), dpi=150)\n",
    "\n",
    "optimum_line, = plt.plot(best_history, color=\"black\", linewidth=0.5, linestyle=\"-.\", label='Global Optimum')\n",
    "ga_line, = plt.plot(ga_history, color=\"green\", linewidth=1.0, linestyle=\"-\", label='GA')\n",
    "oes_line, = plt.plot(oes_history, color=\"orange\", linewidth=1.0, linestyle=\"-\", label='OpenAI-ES')\n",
    "pepg_line, = plt.plot(pepg_history, color=\"blue\", linewidth=1.0, linestyle=\"-\", label='PEPG / NES')\n",
    "cma_line, = plt.plot(cma_history, color=\"red\", linewidth=1.0, linestyle=\"-\", label='CMA-ES')\n",
    "\n",
    "plt.legend(handles=[optimum_line, ga_line, cma_line, pepg_line, oes_line], loc=4)\n",
    "\n",
    "# Set x limits\n",
    "plt.xlim(0,2500)\n",
    "\n",
    "plt.xlabel('generation')\n",
    "plt.ylabel('fitness')\n",
    "\n",
    "# plt.savefig(\"./rastrigin_10d.svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
